{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "torch.set_printoptions(edgeitems=2, threshold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"IMAGEIO_FFMPEG_EXE\"] = \"/usr/bin/ffmpeg\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to the shape of tensors, video data can be seen as equivalent to volumetric data, with `depth` replaced by the `time` dimension. The result is again a 5D tensor with shape `N x C x T x H x W`.\n",
    "\n",
    "There are several formats for video, especially geared towards compression by exploiting redundancies in space and time. Luckily for us, `imageio` reads video data as well. Suppose we'd like to retain 100 consecutive frames in our 512 x 512 RBG video for classifying an action using a convolutional neural network. We first create a reader instance for the video, that will allow us to get information about the video and iterate over the frames in time.\n",
    "Let's see what the meta data for the video looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/usr/bin/ffmpeg'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mimageio\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m reader \u001B[38;5;241m=\u001B[39m \u001B[43mimageio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_reader\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../data/p1ch4/video-cockatoo/cockatoo.mp4\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m meta \u001B[38;5;241m=\u001B[39m reader\u001B[38;5;241m.\u001B[39mget_meta_data()\n\u001B[1;32m      5\u001B[0m meta\n",
      "File \u001B[0;32m~/miniforge3/envs/link_pytorch/lib/python3.10/site-packages/imageio/v2.py:160\u001B[0m, in \u001B[0;36mget_reader\u001B[0;34m(uri, format, mode, **kwargs)\u001B[0m\n\u001B[1;32m    157\u001B[0m imopen_args[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlegacy_mode\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    159\u001B[0m image_file \u001B[38;5;241m=\u001B[39m imopen(uri, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m mode, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mimopen_args)\n\u001B[0;32m--> 160\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimage_file\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlegacy_get_reader\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/link_pytorch/lib/python3.10/site-packages/imageio/core/legacy_plugin_wrapper.py:116\u001B[0m, in \u001B[0;36mLegacyPlugin.legacy_get_reader\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    113\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format\u001B[38;5;241m.\u001B[39mget_reader(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request)\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request\u001B[38;5;241m.\u001B[39mget_file()\u001B[38;5;241m.\u001B[39mseek(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m--> 116\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_format\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_reader\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/link_pytorch/lib/python3.10/site-packages/imageio/core/format.py:221\u001B[0m, in \u001B[0;36mFormat.get_reader\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m select_mode \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodes:\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    219\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFormat \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m cannot read in \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrequest\u001B[38;5;241m.\u001B[39mmode\u001B[38;5;241m.\u001B[39mimage_mode\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m mode\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    220\u001B[0m     )\n\u001B[0;32m--> 221\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mReader\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/link_pytorch/lib/python3.10/site-packages/imageio/core/format.py:312\u001B[0m, in \u001B[0;36mFormat._BaseReaderWriter.__init__\u001B[0;34m(self, format, request)\u001B[0m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request \u001B[38;5;241m=\u001B[39m request\n\u001B[1;32m    311\u001B[0m \u001B[38;5;66;03m# Open the reader/writer\u001B[39;00m\n\u001B[0;32m--> 312\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/link_pytorch/lib/python3.10/site-packages/imageio/plugins/ffmpeg.py:343\u001B[0m, in \u001B[0;36mFfmpegFormat.Reader._open\u001B[0;34m(self, loop, size, dtype, pixelformat, print_info, ffmpeg_params, input_params, output_params, fps)\u001B[0m\n\u001B[1;32m    341\u001B[0m \u001B[38;5;66;03m# Start ffmpeg subprocess and get meta information\u001B[39;00m\n\u001B[1;32m    342\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 343\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_initialize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    344\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mIndexError\u001B[39;00m:\n\u001B[1;32m    345\u001B[0m     \u001B[38;5;66;03m# Specify input framerate again, this time different.\u001B[39;00m\n\u001B[1;32m    346\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m need_input_fps:\n",
      "File \u001B[0;32m~/miniforge3/envs/link_pytorch/lib/python3.10/site-packages/imageio/plugins/ffmpeg.py:494\u001B[0m, in \u001B[0;36mFfmpegFormat.Reader._initialize\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m    492\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_meta\u001B[38;5;241m.\u001B[39mupdate(meta)\n\u001B[1;32m    493\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m index \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 494\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_meta\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_gen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__next__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    495\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    496\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read_gen\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__next__\u001B[39m()\n",
      "File \u001B[0;32m~/miniforge3/envs/link_pytorch/lib/python3.10/site-packages/imageio_ffmpeg/_io.py:267\u001B[0m, in \u001B[0;36mread_frames\u001B[0;34m(path, pix_fmt, bpp, input_params, output_params, bits_per_pixel)\u001B[0m\n\u001B[1;32m    264\u001B[0m cmd \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m input_params \u001B[38;5;241m+\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-i\u001B[39m\u001B[38;5;124m\"\u001B[39m, path]\n\u001B[1;32m    265\u001B[0m cmd \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m pre_output_params \u001B[38;5;241m+\u001B[39m output_params \u001B[38;5;241m+\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m--> 267\u001B[0m p \u001B[38;5;241m=\u001B[39m \u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcmd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstdin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPIPE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstdout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPIPE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstderr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPIPE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_popen_kwargs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprevent_sigint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    275\u001B[0m log_catcher \u001B[38;5;241m=\u001B[39m LogCatcher(p\u001B[38;5;241m.\u001B[39mstderr)\n\u001B[1;32m    277\u001B[0m \u001B[38;5;66;03m# Init policy by which to terminate ffmpeg. May be set to \"kill\" later.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/link_pytorch/lib/python3.10/subprocess.py:971\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001B[0m\n\u001B[1;32m    967\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtext_mode:\n\u001B[1;32m    968\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mTextIOWrapper(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr,\n\u001B[1;32m    969\u001B[0m                     encoding\u001B[38;5;241m=\u001B[39mencoding, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[0;32m--> 971\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexecutable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreexec_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclose_fds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    972\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mpass_fds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcwd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    973\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mstartupinfo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreationflags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshell\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    974\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mp2cread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp2cwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    975\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mc2pread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc2pwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    976\u001B[0m \u001B[43m                        \u001B[49m\u001B[43merrread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    977\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mrestore_signals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    978\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mgid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mumask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    979\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mstart_new_session\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    980\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m    981\u001B[0m     \u001B[38;5;66;03m# Cleanup if the child failed starting.\u001B[39;00m\n\u001B[1;32m    982\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mfilter\u001B[39m(\u001B[38;5;28;01mNone\u001B[39;00m, (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstdin, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstdout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr)):\n",
      "File \u001B[0;32m~/miniforge3/envs/link_pytorch/lib/python3.10/subprocess.py:1847\u001B[0m, in \u001B[0;36mPopen._execute_child\u001B[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001B[0m\n\u001B[1;32m   1845\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errno_num \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1846\u001B[0m         err_msg \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mstrerror(errno_num)\n\u001B[0;32m-> 1847\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001B[1;32m   1848\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m child_exception_type(err_msg)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/usr/bin/ffmpeg'"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "reader = imageio.get_reader('../data/p1ch4/video-cockatoo/cockatoo.mp4')\n",
    "meta = reader.get_meta_data()\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all the information to size the tensor that will store the video frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'meta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m n_channels \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m\n\u001B[0;32m----> 2\u001B[0m n_frames \u001B[38;5;241m=\u001B[39m \u001B[43mmeta\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnframes\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      3\u001B[0m video \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mempty(n_channels, n_frames, \u001B[38;5;241m*\u001B[39mmeta[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msize\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      5\u001B[0m video\u001B[38;5;241m.\u001B[39mshape\n",
      "\u001B[0;31mNameError\u001B[0m: name 'meta' is not defined"
     ]
    }
   ],
   "source": [
    "n_channels = 3\n",
    "n_frames = meta['nframes']\n",
    "video = torch.empty(n_channels, n_frames, *meta['size'])\n",
    "\n",
    "video.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just iterate over the reader and set the values for all three channels into in the proper `i`-th time slice.\n",
    "This might take a few seconds to finish!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, frame_arr \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[43mreader\u001B[49m):\n\u001B[1;32m      2\u001B[0m     frame \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(frame_arr)\u001B[38;5;241m.\u001B[39mfloat()\n\u001B[1;32m      3\u001B[0m     video[:, i] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtranspose(frame, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'reader' is not defined"
     ]
    }
   ],
   "source": [
    "for i, frame_arr in enumerate(reader):\n",
    "    frame = torch.from_numpy(frame_arr).float()\n",
    "    video[:, i] = torch.transpose(frame, 0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, we iterate over individual frames and set each frame in the `C x T x H x W` video tensor, after transposing the channel. We can then obtain a batch by stacking multiple 4D tensors or pre-allocating a 5D tensor with a known batch size and filling it iteratively, clip by clip, assuming clips are trimmed to a fixed number of frames.\n",
    "\n",
    "Equating video data to volumetric data is not the only way to represent video for training purposes. This is a valid strategy if we deal with video bursts of fixed length. An alternative strategy is to resort to network architectures capable of processing long sequences and exploiting short and long-term relationships in time, just like for text or audio.\n",
    "// We'll see this kind of architectures when we take on recurrent networks.\n",
    "\n",
    "This next approach accounts for time along the batch dimension. Hence, we'll build our dataset as a 4D tensor, stacking frame by frame in the batch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_frames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m time_video \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mempty(\u001B[43mn_frames\u001B[49m, n_channels, \u001B[38;5;241m*\u001B[39mmeta[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msize\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, frame \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(reader):\n\u001B[1;32m      4\u001B[0m     frame \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(frame)\u001B[38;5;241m.\u001B[39mfloat()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'n_frames' is not defined"
     ]
    }
   ],
   "source": [
    "time_video = torch.empty(n_frames, n_channels, *meta['size'])\n",
    "\n",
    "for i, frame in enumerate(reader):\n",
    "    frame = torch.from_numpy(frame).float()\n",
    "    time_video[i] = torch.transpose(frame, 0, 2)\n",
    "\n",
    "time_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
